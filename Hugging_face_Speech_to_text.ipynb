{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPofW+tt8H9zdG+XUUad/Ip",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Surabhi6300/Speech_Text_HuggingFace/blob/master/Hugging_face_Speech_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xI7dlZPbRck",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio torch"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7LCdevy3GBHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "FThpjD8FcCYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "z1Uw2IX9cqS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "import IPython.display as display\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6Xqft-psdYjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-960h')\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "id": "WyM9z-bXgkZQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import IPython.display as display\n",
        "\n",
        "def record_audio(filename=\"my_audio.wav\"):\n",
        "    js = \"\"\"\n",
        "    async function record(sec) {\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({audio: true});\n",
        "        const recorder = new MediaRecorder(stream);\n",
        "        let data = [];\n",
        "        recorder.ondataavailable = event => data.push(event.data);\n",
        "        recorder.start();\n",
        "        await new Promise(r => setTimeout(r, sec * 1000));\n",
        "        recorder.stop();\n",
        "        await new Promise(r => recorder.onstop = r);\n",
        "        let audio = new Blob(data);\n",
        "        let reader = new FileReader();\n",
        "        reader.readAsDataURL(audio);\n",
        "        reader.onloadend = () => {\n",
        "            google.colab.kernel.invokeFunction('notebook.recorded', [reader.result], {});\n",
        "        };\n",
        "    }\n",
        "    record(5)  // Record for 5 seconds\n",
        "    \"\"\"\n",
        "    output.register_callback('notebook.recorded', lambda s: open(filename, \"wb\").write(b64decode(s.split(',')[1])))\n",
        "    display.display(display.Javascript(js))\n",
        "\n",
        "record_audio(\"my_audio.wav\")\n"
      ],
      "metadata": {
        "id": "iV6Gt0j8BWss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "# Load the file that was saved\n",
        "audio, sampling_rate = librosa.load(\"my_audio.wav\", sr=16000)\n",
        "\n",
        "print(\"Shape:\", audio.shape)\n",
        "print(\"Sample Rate:\", sampling_rate)\n"
      ],
      "metadata": {
        "id": "oJjsCmXo-Pxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display.Audio('my_audio.wav', autoplay=True)"
      ],
      "metadata": {
        "id": "B9O6G_XmD-dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = processor(audio,sampling_rate=16000,return_tensors = \"pt\").input_values\n",
        "\n",
        "input_values"
      ],
      "metadata": {
        "id": "aJoLjov9IpaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits= model(input_values).logits\n",
        "logits"
      ],
      "metadata": {
        "id": "dnjKQ8RZLaVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids = torch.argmax(logits, dim = -1)"
      ],
      "metadata": {
        "id": "VDjMt-W3L1YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcriptions = processor.decode(predicted_ids[0])\n",
        "transcriptions"
      ],
      "metadata": {
        "collapsed": true,
        "id": "r9PIlInCLzfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}